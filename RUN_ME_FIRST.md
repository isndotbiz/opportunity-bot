# ğŸ¯ START HERE - Production Opportunity Research Bot

## What You Just Got:

âœ… **Real Reddit API scraping** (r/SideProject, r/Entrepreneur, r/SaaS, etc.)
âœ… **Indie Hackers scraping** (verified products with Stripe revenue)
âœ… **Google dorking** (finds hidden opportunities via search queries)
âœ… **Local Qwen AI analysis** (18GB model scoring each opportunity)
âœ… **Semantic RAG database** (ChromaDB for natural language search)
âœ… **Automated daily runs** (cron job setup)

---

## ğŸš€ Quick Start (Choose One):

### Option A: Test with Demo Data (2 minutes)

```bash
# 1. Create virtual environment & install dependencies
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Run demo pipeline (no API keys needed)
python production_opportunity_pipeline.py --demo

# 3. Query results
python query_opportunities.py "high automation passive income"
```

### Option B: Production Scraping (5 minutes)

```bash
# 1. Setup environment
source venv/bin/activate

# 2. Get Reddit API credentials (FREE)
#    Visit: https://www.reddit.com/prefs/apps
#    Create app â†’ Copy client_id & client_secret

# 3. Configure
cp .env.example .env
nano .env  # Add your Reddit credentials

# 4. Start Qwen (if not running)
cd llama-cpp-docker && docker-compose up -d && cd ..

# 5. Run production scraping
python production_opportunity_pipeline.py

# 6. Query your data
python query_opportunities.py "low investment quick wins"
```

---

## ğŸ“ What's in This System:

```
Production Scrapers:
â”œâ”€â”€ scrapers/reddit_scraper.py       â† Real Reddit API (PRAW)
â”œâ”€â”€ scrapers/indiehackers_scraper.py â† Web scraping
â”œâ”€â”€ scrapers/google_dorking.py       â† Google Custom Search
â””â”€â”€ scrapers/config.py               â† Your settings

Main Pipeline:
â”œâ”€â”€ production_opportunity_pipeline.py  â† Full scraping pipeline
â”œâ”€â”€ demo_opportunity_pipeline.py        â† Original demo version
â””â”€â”€ query_opportunities.py              â† Search your RAG

Setup Scripts:
â”œâ”€â”€ setup_venv.sh                    â† Create Python environment
â”œâ”€â”€ setup_cron.sh                    â† Automate daily runs
â””â”€â”€ .env.example                     â† API key template

Documentation:
â”œâ”€â”€ README_PRODUCTION.md             â† Full documentation
â”œâ”€â”€ QUICKSTART.md                    â† 5-minute guide
â””â”€â”€ RUN_ME_FIRST.md                  â† This file!

Qwen LLM:
â””â”€â”€ llama-cpp-docker/                â† Local AI (already running!)
```

---

## ğŸ”‘ API Keys You Need:

### Reddit (Required for Reddit scraping)
- **Where:** https://www.reddit.com/prefs/apps
- **Type:** Script application
- **Cost:** FREE (30 requests/minute)
- **Add to `.env`:**
  ```
  REDDIT_CLIENT_ID=your_id
  REDDIT_CLIENT_SECRET=your_secret
  ```

### Google Custom Search (Optional for dorking)
- **Where:** https://developers.google.com/custom-search/v1/overview
- **Type:** API key + Custom Search Engine ID
- **Cost:** FREE (100 queries/day)
- **Add to `.env`:**
  ```
  GOOGLE_API_KEY=your_key
  GOOGLE_CSE_ID=your_cse_id
  ```

**Without API keys:** Demo mode still works with sample data!

---

## ğŸ“Š What the Pipeline Does:

```
1. SCRAPE (10-15 minutes)
   â”œâ”€ Reddit: 50-100 opportunities
   â”œâ”€ Indie Hackers: 20-30 opportunities
   â””â”€ Google: 10-20 opportunities

2. ANALYZE (with Qwen AI)
   â”œâ”€ Automation Score (0-100)
   â”œâ”€ Legitimacy Score (0-100)
   â”œâ”€ Technical Difficulty (1-5)
   â”œâ”€ Time to Market estimate
   â”œâ”€ Initial Investment estimate
   â””â”€ Risks & Insights

3. STORE (ChromaDB RAG)
   â””â”€ Semantic search database

4. QUERY
   â””â”€ Natural language search
```

---

## ğŸ¯ Example Output:

```bash
$ python production_opportunity_pipeline.py

ğŸ”´ REDDIT SCRAPING:
  ğŸ“¡ Scraping r/SideProject...
    âœ… Found 23 opportunities
  ğŸ“¡ Scraping r/Entrepreneur...
    âœ… Found 31 opportunities

ğŸ’¡ INDIE HACKERS SCRAPING:
  ğŸ“¡ Scraping products...
    âœ… Found 18 opportunities

ğŸ” GOOGLE DORKING:
  ğŸ” Searching: site:reddit.com "made $" automation
    âœ… Found 12 results

âœ… Total: 84 opportunities

ğŸ¤– ANALYZING:
  [1/84] AI Email Newsletter - Automation: 92/100
  [2/84] Twitter Scheduler - Automation: 88/100
  ...

ğŸ’¾ STORED 84 opportunities in RAG

$ python query_opportunities.py "passive income under $1000"

ğŸ“Š Top 3 Results:
1. Notion Template Marketplace
   Automation: 95/100 | Revenue: $2K/mo
   Investment: $200 | Time: 1 month

2. AI Email Curator Tool
   Automation: 92/100 | Revenue: $4K/mo
   Investment: $500 | Time: 6 weeks
```

---

## â° Automate It:

Run scraping daily at 9 AM:

```bash
./setup_cron.sh

# Manually test the cron job
bash run_daily_scraping.sh

# Check logs
tail -f logs/scraping_*.log
```

---

## ğŸ› ï¸ Customize It:

Edit `scrapers/config.py`:

```python
# Monitor different subreddits
REDDIT_SUBREDDITS = [
    "SideProject",
    "EntrepreneurRideAlong",
    "YourNiche",  # Add yours!
]

# Custom search queries
REDDIT_SEARCH_QUERIES = [
    "made $ revenue",
    "your custom query here",
]

# Advanced Google dorks
GOOGLE_DORK_QUERIES = [
    'site:reddit.com "made $" "per month" automation',
    'your custom dork here',
]
```

---

## â“ Troubleshooting:

**Q: "No module named 'praw'"**
A: Activate venv first: `source venv/bin/activate`

**Q: "Reddit API credentials missing"**
A: Get them FREE at https://www.reddit.com/prefs/apps

**Q: "LLM server not running"**
A: Start Qwen: `cd llama-cpp-docker && docker-compose up -d`

**Q: No opportunities found**
A: Use `--demo` flag to test with sample data first

---

## ğŸ“ Learn More:

- **Full Docs:** `README_PRODUCTION.md`
- **Quick Guide:** `QUICKSTART.md`
- **Reddit API:** https://praw.readthedocs.io/
- **Google Dorking:** https://gist.github.com/sundowndev/283efaddbcf896ab405488330d1bbc06

---

## ğŸš€ Your First Command:

```bash
# Activate environment
source venv/bin/activate

# Test with demo mode (no setup needed!)
python production_opportunity_pipeline.py --demo

# Then query results
python query_opportunities.py "high automation"
```

**That's it! You're ready to find automated business opportunities with AI! ğŸ‰**
